import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# ========== 1. Create Simulated Data ==========
data_len = 30
raw_data = np.array([i - 1 if i % 3 == 0 else i for i in range(data_len)])

# Simulate open, close, and volume
opens = raw_data
closes = raw_data + np.random.uniform(-1.0, 1.0, size=data_len)  # slight noise
volumes = np.random.uniform(50, 150, size=data_len)  # random volumes

# Stack features together: shape â†’ (30, 3)
full_data = np.stack([opens, closes, volumes], axis=1)

# ========== 2. Create Sequences ==========
def create_sequences(data, input_size=6, target_size=1, target_index=1):
    X, y = [], []
    for i in range(len(data) - input_size - target_size):
        X.append(data[i:i+input_size])  # full features
        y.append(data[i+input_size:i+input_size+target_size, target_index])  # close prices
    return np.array(X), np.array(y)

input_size = 6
target_size = 1
X, y = create_sequences(full_data, input_size, target_size)

# Convert to PyTorch tensors
X = torch.tensor(X, dtype=torch.float32)          # (batch, seq_len, 3)
y = torch.tensor(y, dtype=torch.float32)          # (batch, 3)

# DataLoader
dataset = TensorDataset(X, y)
loader = DataLoader(dataset, batch_size=1, shuffle=True)

# ========== 3. Define the Model ==========
class SeqPredictor(nn.Module):
    def __init__(self, input_dim=3, hidden_size=256, output_size=3):
        super(SeqPredictor, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        _, (hidden, _) = self.lstm(x)
        out = self.fc(hidden[-1])  # use the last hidden state
        return out

model = SeqPredictor()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# ========== 4. Train the Model ==========
for epoch in range(1000):
    for batch_X, batch_y in loader:
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    if epoch % 20 == 0:
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

# ========== 5. Make a Prediction and Compare ==========
with torch.no_grad():
    # Use the last 5 values in the dataset
    input_seq = full_data[20:25]  # shape: (5, 3)
    test_input = torch.tensor(input_seq[None, ...], dtype=torch.float32)  # Add batch dimension (1, 5, 3)

    prediction = model(test_input)
    predicted_values = prediction.numpy().flatten()

    # True future close prices (index 1 = close)
    true_values = full_data[25:30, 1]

    # Print comparison
    print("\n=== PREDICTION RESULTS ===")
    print("Input Sequence (last 5 steps):")
    print(input_seq)
    print("\nPredicted next 3 close prices:")
    print(predicted_values)
    print("\nActual next 3 close prices:")
    print(true_values)
